{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1: Multilingual Embedding-based Machine Translation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Task) 13 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this homework** **<font color='red'>YOU</font>** will make machine translation system without using parallel corpora, alignment, attention, 100500 depth super-cool recurrent neural network and all that kind superstuff.\n",
    "\n",
    "But even without parallel corpora this system can be good enough (hopefully). \n",
    "\n",
    "For our system we choose two kindred Slavic languages: Ukrainian and Russian. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLEASE CHECK ASSERT, BE SURE THAT YOU IMPLEMENTED ALL THE CODE CORRECT IN FIRST PART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feel the difference!\n",
    "\n",
    "(_синій кіт_ vs. _синій кит_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![blue_cat_blue_whale.png](https://github.com/yandexdataschool/nlp_course/raw/master/resources/blue_cat_blue_whale.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fragment of the Swadesh list for some slavic languages\n",
    "\n",
    "The Swadesh list is a lexicostatistical stuff. It's named after American linguist Morris Swadesh and contains basic lexis. This list are used to define subgroupings of languages, its relatedness.\n",
    "\n",
    "So we can see some kind of word invariance for different Slavic languages.\n",
    "\n",
    "\n",
    "| Russian         | Belorussian              | Ukrainian               | Polish             | Czech                         | Bulgarian            |\n",
    "|-----------------|--------------------------|-------------------------|--------------------|-------------------------------|-----------------------|\n",
    "| женщина         | жанчына, кабета, баба    | жінка                   | kobieta            | žena                          | жена                  |\n",
    "| мужчина         | мужчына                  | чоловік, мужчина        | mężczyzna          | muž                           | мъж                   |\n",
    "| человек         | чалавек                  | людина, чоловік         | człowiek           | člověk                        | човек                 |\n",
    "| ребёнок, дитя   | дзіця, дзіцёнак, немаўля | дитина, дитя            | dziecko            | dítě                          | дете                  |\n",
    "| жена            | жонка                    | дружина, жінка          | żona               | žena, manželka, choť          | съпруга, жена         |\n",
    "| муж             | муж, гаспадар            | чоловiк, муж            | mąż                | muž, manžel, choť             | съпруг, мъж           |\n",
    "| мать, мама      | маці, матка              | мати, матір, неня, мама | matka              | matka, máma, 'стар.' mateř    | майка                 |\n",
    "| отец, тятя      | бацька, тата             | батько, тато, татусь    | ojciec             | otec                          | баща, татко           |\n",
    "| много           | шмат, багата             | багато                  | wiele              | mnoho, hodně                  | много                 |\n",
    "| несколько       | некалькі, колькі         | декілька, кілька        | kilka              | několik, pár, trocha          | няколко               |\n",
    "| другой, иной    | іншы                     | інший                   | inny               | druhý, jiný                   | друг                  |\n",
    "| зверь, животное | жывёла, звер, істота     | тварина, звір           | zwierzę            | zvíře                         | животно               |\n",
    "| рыба            | рыба                     | риба                    | ryba               | ryba                          | риба                  |\n",
    "| птица           | птушка                   | птах, птиця             | ptak               | pták                          | птица                 |\n",
    "| собака, пёс     | сабака                   | собака, пес             | pies               | pes                           | куче, пес             |\n",
    "| вошь            | вош                      | воша                    | wesz               | veš                           | въшка                 |\n",
    "| змея, гад       | змяя                     | змія, гад               | wąż                | had                           | змия                  |\n",
    "| червь, червяк   | чарвяк                   | хробак, черв'як         | robak              | červ                          | червей                |\n",
    "| дерево          | дрэва                    | дерево                  | drzewo             | strom, dřevo                  | дърво                 |\n",
    "| лес             | лес                      | ліс                     | las                | les                           | гора, лес             |\n",
    "| палка           | кій, палка               | палиця                  | patyk, pręt, pałka | hůl, klacek, prut, kůl, pálka | палка, пръчка, бастун |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the context distribution of these languages demonstrates even more invariance. And we can use this fact for our purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download embeddings here:\n",
    "* [cc.uk.300.vec.zip](https://www.dropbox.com/scl/fo/czrdhfndzvirs0c3x4adh/AIDkoaHAyd3bcpAegJ4bz3A?rlkey=f7xnl9lqiahjbor3ucxyy6u6p&st=ee70k4ik&dl=0)\n",
    "* [cc.ru.300.vec.zip](https://www.dropbox.com/scl/fo/czrdhfndzvirs0c3x4adh/AIDkoaHAyd3bcpAegJ4bz3A?rlkey=f7xnl9lqiahjbor3ucxyy6u6p&st=ee70k4ik&dl=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load embeddings for ukrainian and russian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_emb = KeyedVectors.load_word2vec_format(\"cc.uk.300.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_emb = KeyedVectors.load_word2vec_format(\"cc.ru.300.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('август', 1.0000001192092896),\n",
       " ('июль', 0.9383152723312378),\n",
       " ('сентябрь', 0.9240029454231262),\n",
       " ('июнь', 0.9222574830055237),\n",
       " ('октябрь', 0.9095539450645447),\n",
       " ('ноябрь', 0.8930036425590515),\n",
       " ('апрель', 0.8729087114334106),\n",
       " ('декабрь', 0.8652557730674744),\n",
       " ('март', 0.8545795679092407),\n",
       " ('февраль', 0.8401415944099426)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_emb.most_similar([ru_emb[\"август\"]], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('серпень', 0.9999998807907104),\n",
       " ('липень', 0.9096441268920898),\n",
       " ('вересень', 0.9016969203948975),\n",
       " ('червень', 0.8992518782615662),\n",
       " ('жовтень', 0.8810408115386963),\n",
       " ('листопад', 0.8787633180618286),\n",
       " ('квітень', 0.8592804670333862),\n",
       " ('грудень', 0.8586863279342651),\n",
       " ('травень', 0.840811014175415),\n",
       " ('лютий', 0.8256431221961975)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk_emb.most_similar([uk_emb[\"серпень\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load small dictionaries for correspoinding words pairs as trainset and testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word_pairs(filename):\n",
    "    uk_ru_pairs = []\n",
    "    uk_vectors = []\n",
    "    ru_vectors = []\n",
    "    with open(filename, \"r\") as inpf:\n",
    "        for line in inpf:\n",
    "            uk, ru = line.rstrip().split(\"\\t\")\n",
    "            if uk not in uk_emb or ru not in ru_emb:\n",
    "                continue\n",
    "            uk_ru_pairs.append((uk, ru))\n",
    "            uk_vectors.append(uk_emb[uk])\n",
    "            ru_vectors.append(ru_emb[ru])\n",
    "    return uk_ru_pairs, np.array(uk_vectors), np.array(ru_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_ru_train, X_train, Y_train = load_word_pairs(\"ukr_rus.train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_ru_test, X_test, Y_test = load_word_pairs(\"ukr_rus.test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding space mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $x_i \\in \\mathrm{R}^d$ be the distributed representation of word $i$ in the source language, and $y_i \\in \\mathrm{R}^d$ is the vector representation of its translation. Our purpose is to learn such linear transform $W$ that minimizes euclidian distance between $Wx_i$ and $y_i$ for some subset of word embeddings. Thus we can formulate so-called Procrustes problem:\n",
    "\n",
    "$$W^*= \\arg\\min_W \\sum_{i=1}^n||Wx_i - y_i||_2$$\n",
    "or\n",
    "$$W^*= \\arg\\min_W ||WX - Y||_F$$\n",
    "\n",
    "where $||*||_F$ - Frobenius norm.\n",
    "\n",
    "In Greek mythology, Procrustes or \"the stretcher\" was a rogue smith and bandit from Attica who attacked people by stretching them or cutting off their legs, so as to force them to fit the size of an iron bed. We make same bad things with source embedding space. Our Procrustean bed is target embedding space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![embedding_mapping.png](https://github.com/yandexdataschool/nlp_course/raw/master/resources/embedding_mapping.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![procrustes.png](https://github.com/yandexdataschool/nlp_course/raw/master/resources/procrustes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But wait...$W^*= \\arg\\min_W \\sum_{i=1}^n||Wx_i - y_i||_2$ looks like simple multiple linear regression (without intercept fit). So let's code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1927 pairs.\n",
      "First 5 pairs: [('iмовірно', 'вероятно'), ('iснує', 'существует'), ('iспит', 'экзамен'), ('абияк', 'как-нибудь'), ('або', 'или')]\n"
     ]
    }
   ],
   "source": [
    "# Load word pairs from training file\n",
    "pairs = []\n",
    "try:\n",
    "    with open(r\"C:\\Users\\Admin\\Desktop\\sabaq(C3T2)\\C3T2\\NLP\\Assignment 1\\ukr_rus.train.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            uk_word, ru_word = line.strip().split()\n",
    "            pairs.append((uk_word, ru_word))\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Training file 'ukr_rus.train.txt' not found. Check your file path.\")\n",
    "\n",
    "# Debug loaded pairs\n",
    "print(f\"Loaded {len(pairs)} pairs.\")\n",
    "print(f\"First 5 pairs: {pairs[:5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered pairs: 1840\n"
     ]
    }
   ],
   "source": [
    "# Filter pairs to ensure both words have embeddings\n",
    "pairs = [(uk, ru) for uk, ru in pairs if uk in uk_emb and ru in ru_emb]\n",
    "\n",
    "# Debugging length of pairs\n",
    "print(f\"Filtered pairs: {len(pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (1840, 300)\n",
      "Y_test shape: (1840, 300)\n"
     ]
    }
   ],
   "source": [
    "# Initialize test matrices\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "# Build X_test and Y_test matrices\n",
    "for uk_word, ru_word in pairs:\n",
    "    if uk_word in uk_emb and ru_word in ru_emb:\n",
    "        X_test.append(uk_emb[uk_word])\n",
    "        Y_test.append(ru_emb[ru_word])\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_test = np.array(X_test)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "# Debugging shapes\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"Y_test shape: {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping coefficients shape: (300, 300)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize and train the linear regression model\n",
    "mapping = LinearRegression()\n",
    "mapping.fit(X_train, Y_train)\n",
    "\n",
    "# Debugging coefficients\n",
    "print(f\"Mapping coefficients shape: {mapping.coef_.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped vectors shape: (1840, 300)\n"
     ]
    }
   ],
   "source": [
    "mapped_vectors = mapping.predict(X_test)\n",
    "print(f\"Mapped vectors shape: {mapped_vectors.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at neigbours of the vector of word _\"серпень\"_ (_\"август\"_ in Russian) after linear transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('апрель', 0.8541591763496399), ('июнь', 0.8411963582038879), ('март', 0.8397400379180908), ('сентябрь', 0.8359215259552002), ('февраль', 0.8328747749328613)]\n"
     ]
    }
   ],
   "source": [
    "# Example: Map Ukrainian word \"серпень\" to Russian\n",
    "august = mapping.predict(uk_emb[\"серпень\"].reshape(1, -1))\n",
    "print(ru_emb.most_similar(august, topn=5))  # Get top-5 similar Russian words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that neighbourhood of this embedding cosists of different months, but right variant is on the ninth place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As quality measure we will use precision top-1, top-5 and top-10 (for each transformed Ukrainian embedding we count how many right target pairs are found in top N nearest neighbours in Russian embedding space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "\n",
    "def precision(pairs, mapped_vectors, topn=1):\n",
    "    \"\"\"\n",
    "    :args:\n",
    "        pairs = list of right word pairs [(uk_word_0, ru_word_0), ...]\n",
    "        mapped_vectors = list of embeddings after mapping from source embedding space to destination embedding space\n",
    "        topn = the number of nearest neighbours in destination embedding space to choose from\n",
    "    :returns:\n",
    "        precision_val, float number, total number of words for those we can find right translation at top K.\n",
    "    \"\"\"\n",
    "    assert len(pairs) == len(mapped_vectors)\n",
    "    num_matches = 0\n",
    "\n",
    "    # Extract the embeddings of the Russian words in the pairs\n",
    "    ru_words = [ru for _, ru in pairs]\n",
    "    ru_embeddings = np.array([ru_emb[word] for word in ru_words if word in ru_emb])\n",
    "\n",
    "    # Compute cosine similarities\n",
    "    distances = cdist(mapped_vectors, ru_embeddings, metric=\"cosine\")\n",
    "\n",
    "    # Find nearest neighbors and check if the correct Russian word is within the top 'topn'\n",
    "    for i, (_, ru) in enumerate(pairs):\n",
    "        if ru not in ru_emb:\n",
    "            continue\n",
    "        nearest_indices = np.argsort(distances[i])[:topn]\n",
    "        nearest_words = [ru_words[idx] for idx in nearest_indices]\n",
    "        if ru in nearest_words:\n",
    "            num_matches += 1\n",
    "\n",
    "    precision_val = num_matches / len(pairs)\n",
    "    return precision_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pairs: 1840\n",
      "Number of mapped vectors: 1840\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of pairs: {len(pairs)}\")\n",
    "print(f\"Number of mapped vectors: {len(mapped_vectors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered X_train shape: (1840, 300)\n",
      "Filtered Y_train shape: (1840, 300)\n"
     ]
    }
   ],
   "source": [
    "# Filter pairs to ensure both words have embeddings\n",
    "filtered_pairs = [(uk, ru) for uk, ru in pairs if uk in uk_emb and ru in ru_emb]\n",
    "\n",
    "# Prepare training data again based on filtered pairs\n",
    "X_train = np.array([uk_emb[uk] for uk, ru in filtered_pairs])\n",
    "Y_train = np.array([ru_emb[ru] for uk, ru in filtered_pairs])\n",
    "\n",
    "# Verify shapes of training data\n",
    "print(f\"Filtered X_train shape: {X_train.shape}\")\n",
    "print(f\"Filtered Y_train shape: {Y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@1: 0.8429347826086957\n"
     ]
    }
   ],
   "source": [
    "# Map the filtered Ukrainian embeddings to Russian space\n",
    "mapped_vectors = mapping.predict(X_train)\n",
    "\n",
    "# Re-run precision calculation\n",
    "precision_val = precision(filtered_pairs, mapped_vectors, topn=1)\n",
    "print(f\"Precision@1: {precision_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Correcting `august` to a 2D array for precision calculation\u001b[39;00m\n\u001b[0;32m      2\u001b[0m mapped_august \u001b[38;5;241m=\u001b[39m mapping\u001b[38;5;241m.\u001b[39mpredict(uk_emb[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mсерпень\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m precision([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mсерпень\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mавгуст\u001b[39m\u001b[38;5;124m\"\u001b[39m)], mapped_august, topn\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m precision([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mсерпень\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mавгуст\u001b[39m\u001b[38;5;124m\"\u001b[39m)], mapped_august, topn\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m precision([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mсерпень\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mавгуст\u001b[39m\u001b[38;5;124m\"\u001b[39m)], mapped_august, topn\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Correcting `august` to a 2D array for precision calculation\n",
    "mapped_august = mapping.predict(uk_emb[\"серпень\"].reshape(1, -1))\n",
    "assert precision([(\"серпень\", \"август\")], mapped_august, topn=5) == 0.0\n",
    "assert precision([(\"серпень\", \"август\")], mapped_august, topn=9) == 1.0\n",
    "assert precision([(\"серпень\", \"август\")], mapped_august, topn=10) == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Precision calculations with filtered pairs\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m mapped_test_vectors \u001b[38;5;241m=\u001b[39m \u001b[43mmapping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m precision(filtered_pairs, mapped_test_vectors, topn\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m precision(filtered_pairs, mapped_test_vectors, topn\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:306\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    293\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:285\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    283\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 285\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m     coef_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m coef_\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1050\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1043\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1044\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1045\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1046\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1047\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1048\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1049\u001b[0m             )\n\u001b[1;32m-> 1050\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1054\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1055\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1056\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# Precision calculations with filtered pairs\n",
    "mapped_test_vectors = mapping.predict(X_test)\n",
    "assert precision(filtered_pairs, mapped_test_vectors, topn=1) == 0.0\n",
    "assert precision(filtered_pairs, mapped_test_vectors, topn=10) == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run precision function on corrected test data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m precision_top1 \u001b[38;5;241m=\u001b[39m precision(pairs, \u001b[43mmapping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m, topn\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m precision_top5 \u001b[38;5;241m=\u001b[39m precision(pairs, mapping\u001b[38;5;241m.\u001b[39mpredict(X_test), topn\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Assert precision meets the requirements\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:306\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    293\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:285\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    283\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 285\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m     coef_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m coef_\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1050\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1043\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1044\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1045\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1046\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1047\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1048\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1049\u001b[0m             )\n\u001b[1;32m-> 1050\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1054\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1055\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1056\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# Run precision function on corrected test data\n",
    "precision_top1 = precision(pairs, mapping.predict(X_test), topn=1)\n",
    "precision_top5 = precision(pairs, mapping.predict(X_test), topn=5)\n",
    "\n",
    "# Assert precision meets the requirements\n",
    "assert precision_top1 >= 0.635\n",
    "assert precision_top5 >= 0.813\n",
    "\n",
    "print(f\"Precision@1: {precision_top1}\")\n",
    "print(f\"Precision@5: {precision_top5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making it better (orthogonal Procrustean problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be shown (see original paper) that a self-consistent linear mapping between semantic spaces should be orthogonal. \n",
    "We can restrict transform $W$ to be orthogonal. Then we will solve next problem:\n",
    "\n",
    "$$W^*= \\arg\\min_W ||WX - Y||_F \\text{, where: } W^TW = I$$\n",
    "\n",
    "$$I \\text{- identity matrix}$$\n",
    "\n",
    "Instead of making yet another regression problem we can find optimal orthogonal transformation using singular value decomposition. It turns out that optimal transformation $W^*$ can be expressed via SVD components:\n",
    "$$X^TY=U\\Sigma V^T\\text{, singular value decompostion}$$\n",
    "$$W^*=UV^T$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_transform(X_train, Y_train):\n",
    "    \"\"\"\n",
    "    Learn the transformation matrix W* that maps X_train to Y_train.\n",
    "    :returns: W* - a float matrix of shape [emb_dim x emb_dim]\n",
    "    \"\"\"\n",
    "    # Compute W* using the least squares method\n",
    "    W_star = np.linalg.lstsq(X_train, Y_train, rcond=None)[0]\n",
    "    return W_star\n",
    "\n",
    "# Calculate W\n",
    "W = learn_transform(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = learn_transform(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('апрель', 0.8541285991668701),\n",
       " ('июнь', 0.8411203622817993),\n",
       " ('март', 0.839699387550354),\n",
       " ('сентябрь', 0.8359870314598083),\n",
       " ('февраль', 0.832929790019989),\n",
       " ('октябрь', 0.8311845660209656),\n",
       " ('ноябрь', 0.8278924226760864),\n",
       " ('июль', 0.823452889919281),\n",
       " ('август', 0.8120501637458801),\n",
       " ('декабрь', 0.803900420665741)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_emb.most_similar([np.matmul(uk_emb[\"серпень\"], W)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 300 is different from 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m precision(uk_ru_test, \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.653\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m precision(uk_ru_test, np\u001b[38;5;241m.\u001b[39mmatmul(X_test, W), \u001b[38;5;241m5\u001b[39m) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.824\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 300 is different from 0)"
     ]
    }
   ],
   "source": [
    "assert precision(uk_ru_test, np.matmul(X_test, W)) >= 0.653\n",
    "assert precision(uk_ru_test, np.matmul(X_test, W), 5) >= 0.824"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UK-RU Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to make simple word-based translator: for each word in source language in shared embedding space we find the nearest in target language.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fairy_tale.txt\", \"r\") as inpf:\n",
    "    uk_sentences = [line.rstrip().lower() for line in inpf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    \"\"\"\n",
    "    Translate a sentence from Ukrainian to Russian.\n",
    "    \"\"\"\n",
    "    words = sentence.split()\n",
    "    translated_words = []\n",
    "    for word in words:\n",
    "        if word in uk_emb:\n",
    "            # Map the word embedding\n",
    "            mapped_vector = np.matmul(uk_emb[word], W)\n",
    "            # Find the closest Russian word\n",
    "            similar_words = ru_emb.similar_by_vector(mapped_vector, topn=1)\n",
    "            translated_words.append(similar_words[0][0])\n",
    "        else:\n",
    "            translated_words.append(word)  # Keep the word as is if not in embeddings\n",
    "    return \" \".join(translated_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m translate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m translate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1 , 3\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1 , 3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m translate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mкіт зловив мишу\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mкот поймал мышку\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert translate(\".\") == \".\"\n",
    "assert translate(\"1 , 3\") == \"1 , 3\"\n",
    "assert translate(\"кіт зловив мишу\") == \"кот поймал мышку\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src: р›рёсѓрёс‡рєр° - сѓрµсѓс‚сђрёс‡рєр° с– рірѕрірє - рїр°рѕс–р±сђр°с‚\n",
      "dst: р›рёсѓрёс‡рєр° – сѓрµсѓс‚сђрёс‡рєр° с– рірѕрірє – рїр°рѕс–р±сђр°с‚\n",
      "\n",
      "src: рїрє р±сѓр»р° сѓрѕр±с– р»рёсѓрёс‡рєр° с‚р° р·сђрѕр±рёр»р° с…р°с‚рєсѓ, с‚р° р№ р¶рёрірµ. рђ с†рµ рїсђрёс…рѕрґсџс‚сњ с…рѕр»рѕрґрё. рћс‚ р»рёсѓрёс‡рєр° р·р°рјрµсђр·р»р° с‚р° р№ рїрѕр±с–рір»р° рі сѓрµр»рѕ рірѕрірѕсћ рґрѕр±сѓрір°с‚сњ, с‰рѕр± рірёс‚рѕрїрёс‚рё. рџсђрёр±с–рір°с” рґрѕ рѕрґрѕрѕс— р±р°р±рё с‚р° р№ рєр°р¶рµ:\n",
      "dst: рїрє р±сѓр»р° сѓрѕр±с– р»рёсѓрёс‡рєр° с‚р° р·сђрѕр±рёр»р° с…р°с‚рєсѓ, с‚р° р№ р¶рёрірµ. рђ с†рµ рїсђрёс…рѕрґсџс‚сњ с…рѕр»рѕрґрё. рћс‚ р»рёсѓрёс‡рєр° р·р°рјрµсђр·р»р° с‚р° р№ рїрѕр±с–рір»р° пя сѓрµр»рѕ рірѕрірѕсћ рґрѕр±сѓрір°с‚сњ, с‰рѕр± рірёс‚рѕрїрёс‚рё. рџсђрёр±с–рір°с” рґрѕ рѕрґрѕрѕс— р±р°р±рё с‚р° р№ рєр°р¶рµ:\n",
      "\n",
      "src: вђ” р—рґрѕсђрѕріс– р±сѓр»рё, р±р°р±сѓсѓсћ! р— рѕрµрґс–р»рµсћ... рџрѕр·рёс‡с‚рµ рјрµрѕс– рѕрірѕсћ, сџ рір°рј рѕрґсѓр»сѓр¶сѓ.\n",
      "dst: вђ” р—рґрѕсђрѕріс– р±сѓр»рё, р±р°р±сѓсѓсћ! р— рѕрµрґс–р»рµсћ... рџрѕр·рёс‡с‚рµ рјрµрѕс– рѕрірѕсћ, , рір°рј рѕрґсѓр»сѓр¶сѓ.\n",
      "\n",
      "src: вђ” р”рѕр±сђрµ, вђ” рєр°р¶рµ, вђ” р»рёсѓрёс‡рєрѕ - сѓрµсѓс‚сђрёс‡рєрѕ. рўс–рґр°р№ рїрѕрісђс–р№сѓсџ с‚сђрѕс…рё, рїрѕрєрё сџ рїрёсђс–р¶рµс‡рєрё рїрѕрірёр±рёсђр°сћ р· рїрµс‡с–!\n",
      "dst: вђ” р”рѕр±сђрµ, вђ” рєр°р¶рµ, вђ” р»рёсѓрёс‡рєрѕ – сѓрµсѓс‚сђрёс‡рєрѕ. рўс–рґр°р№ рїрѕрісђс–р№сѓсџ с‚сђрѕс…рё, рїрѕрєрё , рїрёсђс–р¶рµс‡рєрё рїрѕрірёр±рёсђр°сћ р· рїрµс‡с–!\n",
      "\n",
      "src: рђ р±р°р±р° рјр°рєрѕріс– рїрёсђс–р¶рєрё рїрµрєр»р°. рћс‚ р±р°р±р° рірёр±рёсђр°с” рїрёсђс–р¶рєрё с‚р° рѕр° сѓс‚рѕр»с– рєр»р°рґрµ, с‰рѕр± рїсђрѕс…рѕр»рѕр»рё; р° р»рёсѓрёс‡рєр° рїс–рґрір»сџрґс–р»р° с‚р° р·р° рїрёсђс–рі, с‚р° р· с…р°с‚рё... р’рёс—р»р° рјр°с‡рѕрє с–р· сѓрµсђрµрґрёрѕрё, р° с‚сѓрґрё рѕр°рїс…р°р»р° сѓрјс–с‚с‚сџс‡рєр°, сѓс‚сѓр»рёр»р° с‚р° р№ р±с–р¶рёс‚сњ.\n",
      "dst: рђ р±р°р±р° рјр°рєрѕріс– рїрёсђс–р¶рєрё рїрµрєр»р°. рћс‚ р±р°р±р° рірёр±рёсђр°с” рїрёсђс–р¶рєрё с‚р° рѕр° сѓс‚рѕр»с– рєр»р°рґрµ, с‰рѕр± рїсђрѕс…рѕр»рѕр»рё; р° р»рёсѓрёс‡рєр° рїс–рґрір»сџрґс–р»р° с‚р° р·р° рїрёсђс–рі, с‚р° р· с…р°с‚рё... р’рёс—р»р° рјр°с‡рѕрє с–р· сѓрµсђрµрґрёрѕрё, р° с‚сѓрґрё рѕр°рїс…р°р»р° сѓрјс–с‚с‚сџс‡рєр°, сѓс‚сѓр»рёр»р° с‚р° р№ р±с–р¶рёс‚сњ.\n",
      "\n",
      "src: рћс‚ р±с–р¶рёс‚сњ, р° с…р»рѕрїс†с– с‚рѕрір°сђ р¶рµрѕсѓс‚сњ рґрѕ рірѕрґрё.\n",
      "dst: рћс‚ р±с–р¶рёс‚сњ, р° с…р»рѕрїс†с– с‚рѕрір°сђ р¶рµрѕсѓс‚сњ рґрѕ рірѕрґрё.\n",
      "\n",
      "src: вђ” р—рґрѕсђрѕріс– р±сѓр»рё, с…р»рѕрїс†с–!\n",
      "dst: вђ” р—рґрѕсђрѕріс– р±сѓр»рё, с…р»рѕрїс†с–!\n",
      "\n",
      "src: вђ” р—рґрѕсђрѕрір°, р»рёсѓрёс‡рєрѕ - сѓрµсѓс‚сђрёс‡рєрѕ!\n",
      "dst: вђ” р—рґрѕсђрѕрір°, р»рёсѓрёс‡рєрѕ – сѓрµсѓс‚сђрёс‡рєрѕ!\n",
      "\n",
      "src: вђ” рџсђрѕрјс–рѕсџр№с‚рµ рјрµрѕс– р±рёс‡рєр° - с‚сђрµс‚сџс‡рєр° рѕр° рјр°рєрѕрірёр№ рїрёсђс–р¶рѕрє!\n",
      "dst: вђ” рџсђрѕрјс–рѕсџр№с‚рµ рјрµрѕс– р±рёс‡рєр° – с‚сђрµс‚сџс‡рєр° рѕр° рјр°рєрѕрірёр№ рїрёсђс–р¶рѕрє!\n",
      "\n",
      "src: вђ” р”рѕр±сђрµ, вђ” рєр°р¶сѓс‚сњ.\n",
      "dst: вђ” р”рѕр±сђрµ, вђ” рєр°р¶сѓс‚сњ.\n",
      "\n",
      "src: вђ” рўс–р»сњрєрё, вђ” рєр°р¶рµ, вђ” с‚рµрїрµсђ рѕрµ с—р¶с‚рµ, р° сџрє сџ рірёр±с–р¶сѓ р· сѓрµр»р°, с‚рѕ с‚рѕрґс–.\n",
      "dst: вђ” рўс–р»сњрєрё, вђ” рєр°р¶рµ, вђ” с‚рµрїрµсђ рѕрµ с—р¶с‚рµ, р° сџрє , рірёр±с–р¶сѓ р· сѓрµр»р°, с‚рѕ с‚рѕрґс–.\n",
      "\n",
      "src: рћс‚ рїрѕрјс–рѕсџр»рёсѓсњ. р›рёсѓрёс‡рєр° р·р° р±рёс‡рєр° вђ” с‚р° рі р»с–сѓ. рђ с…р»рѕрїс†с– рґрѕ рїрёсђс–р¶рєр° вђ” р° с‚р°рј сѓрјс–с‚с‚сџрѕрєрѕ.\n",
      "dst: рћс‚ рїрѕрјс–рѕсџр»рёсѓсњ. р›рёсѓрёс‡рєр° р·р° р±рёс‡рєр° вђ” с‚р° пя р»с–сѓ. рђ с…р»рѕрїс†с– рґрѕ рїрёсђс–р¶рєр° вђ” р° с‚р°рј сѓрјс–с‚с‚сџрѕрєрѕ.\n",
      "\n",
      "src: рћс‚ рїсђрёр±с–рір»р° р»рёсѓрёс‡рєр° рґрѕ сѓрірѕс”с— с…р°с‚рєрё, рірёсђсѓр±р°р»р° рґрµсђрµрірѕ, р·сђрѕр±рёр»р° сѓр°рѕрєрё, р·р°рїсђсџрір»р° р±рёс‡рєр° вђ” с–рґрµ. рђр¶ р±с–р¶рёс‚сњ рірѕрірє:\n",
      "dst: рћс‚ рїсђрёр±с–рір»р° р»рёсѓрёс‡рєр° рґрѕ сѓрірѕс”с— с…р°с‚рєрё, рірёсђсѓр±р°р»р° рґрµсђрµрірѕ, р·сђрѕр±рёр»р° сѓр°рѕрєрё, р·р°рїсђсџрір»р° р±рёс‡рєр° вђ” с–рґрµ. рђр¶ р±с–р¶рёс‚сњ рірѕрірє:\n",
      "\n",
      "src: вђ” р—рґрѕсђрѕрір°, р»рёсѓрёс‡рєрѕ - сѓрµсѓс‚сђрёс‡рєрѕ!\n",
      "dst: вђ” р—рґрѕсђрѕрір°, р»рёсѓрёс‡рєрѕ – сѓрµсѓс‚сђрёс‡рєрѕ!\n",
      "\n",
      "src: вђ” р—рґрѕсђрѕрі, рірѕріс‡рёрєсѓ - р±сђр°с‚рёрєсѓ!\n",
      "dst: вђ” р—рґрѕсђрѕрі, рірѕріс‡рёрєсѓ – р±сђр°с‚рёрєсѓ!\n",
      "\n",
      "src: вђ” р”рµ с‚рё рір·сџр»р° р±рёс‡рєр° - с‚сђрµс‚сџс‡рєр° с– сѓр°рѕрєрё?\n",
      "dst: вђ” р”рµ с‚рё рір·сџр»р° р±рёс‡рєр° – с‚сђрµс‚сџс‡рєр° с– сѓр°рѕрєрё?\n",
      "\n",
      "src: вђ” р—сђрѕр±рёр»р° сѓрѕр±с–!\n",
      "dst: вђ” р—сђрѕр±рёр»р° сѓрѕр±с–!\n",
      "\n",
      "src: вђ” рџс–рґрірµр·рё р¶, вђ” рєр°р¶рµ, вђ” рјрµрѕрµ, р»рёсѓрёс‡рєрѕ - сѓрµсѓс‚сђрёс‡рєрѕ!\n",
      "dst: вђ” рџс–рґрірµр·рё р¶, вђ” рєр°р¶рµ, вђ” рјрµрѕрµ, р»рёсѓрёс‡рєрѕ – сѓрµсѓс‚сђрёс‡рєрѕ!\n",
      "\n",
      "src: вђ” р•, рєсѓрґрё сџ с‚рµр±рµ ріс–р·сњрјсѓ? рўрё рјрµрѕс– р№ сѓр°рѕрєрё рїрѕр»р°рјр°с”с€!\n",
      "dst: вђ” р•, рєсѓрґрё , с‚рµр±рµ ріс–р·сњрјсѓ? рўрё рјрµрѕс– р№ сѓр°рѕрєрё рїрѕр»р°рјр°с”с€!\n",
      "\n",
      "src: вђ” рќс–, вђ” рєр°р¶рµ, вђ” сџ с‚с–р»сњрєрё рѕрґрѕсѓ рѕс–р¶рєсѓ рїрѕр»рѕр¶сѓ.\n",
      "dst: вђ” рќс–, вђ” рєр°р¶рµ, вђ” , с‚с–р»сњрєрё рѕрґрѕсѓ рѕс–р¶рєсѓ рїрѕр»рѕр¶сѓ.\n",
      "\n",
      "src: вђ” рќсѓ, рєр»р°рґрё!\n",
      "dst: вђ” рќсѓ, рєр»р°рґрё!\n",
      "\n",
      "src: рћс‚ рѕрґвђ™с—с…р°р»рё с‚сђрѕс…рё, рірѕрірє с– рєр°р¶рµ:\n",
      "dst: рћс‚ рѕрґвђ™с—с…р°р»рё с‚сђрѕс…рё, рірѕрірє с– рєр°р¶рµ:\n",
      "\n",
      "src: вђ” рџрѕр»рѕр¶сѓ сџ, р»рёсѓрёс‡рєрѕ - сѓрµсѓс‚сђрёс‡рєрѕ, р№ рґсђсѓрісѓ рѕс–р¶рєсѓ!\n",
      "dst: вђ” рџрѕр»рѕр¶сѓ сџ, р»рёсѓрёс‡рєрѕ – сѓрµсѓс‚сђрёс‡рєрѕ, р№ рґсђсѓрісѓ рѕс–р¶рєсѓ!\n",
      "\n",
      "src: вђ” р•, рірѕріс‡рёрєсѓ - р±сђр°с‚рёрєсѓ, с‚рё рјрµрѕс– р№ сѓр°рѕрєрё рїрѕр»р°рјр°с”с€!\n",
      "dst: вђ” р•, рірѕріс‡рёрєсѓ – р±сђр°с‚рёрєсѓ, с‚рё рјрµрѕс– р№ сѓр°рѕрєрё рїрѕр»р°рјр°с”с€!\n",
      "\n",
      "src: вђ” рќс–, вђ” рєр°р¶рµ, вђ” рѕрµ рїрѕр»р°рјр°сћ!\n",
      "dst: вђ” рќс–, вђ” рєр°р¶рµ, вђ” рѕрµ рїрѕр»р°рјр°сћ!\n",
      "\n",
      "src: вђ” рќсѓ, рєр»р°рґрё!\n",
      "dst: вђ” рќсѓ, рєр»р°рґрё!\n",
      "\n",
      "src: р’рѕрірє с– рїрѕр»рѕр¶рёрі. р†рґсѓс‚сњ, с—рґсѓс‚сњ, рєрѕр»рё с†рµ с‰рѕсѓсњ вђ” с‚сђс–сѓсњ.\n",
      "dst: р’рѕрірє с– рїрѕр»рѕр¶рёрі. р†рґсѓс‚сњ, с—рґсѓс‚сњ, рєрѕр»рё с†рµ с‰рѕсѓсњ вђ” с‚сђс–сѓсњ.\n",
      "\n",
      "src: вђ” р•, рірѕріс‡рёрєсѓ - р±сђр°с‚рёрєсѓ, с‚рё рјрµрѕс– рір¶рµ р№ сѓр°рѕрєрё р»р°рјр°с”с€!\n",
      "dst: вђ” р•, рірѕріс‡рёрєсѓ – р±сђр°с‚рёрєсѓ, с‚рё рјрµрѕс– рір¶рµ р№ сѓр°рѕрєрё р»р°рјр°с”с€!\n",
      "\n",
      "src: вђ” рќс– р»рёсѓрёс‡рєрѕ - сѓрµсѓс‚сђрёс‡рєрѕ, с‚рѕ сџ рѕсђс–с€рѕрє сђрѕр·рєсѓсѓрёрі.\n",
      "dst: вђ” рќс– р»рёсѓрёс‡рєрѕ – сѓрµсѓс‚сђрёс‡рєрѕ, с‚рѕ , рѕсђс–с€рѕрє сђрѕр·рєсѓсѓрёрі.\n",
      "\n",
      "src: вђ” рќсѓ, рір»сџрґрё!\n",
      "dst: вђ” рќсѓ, рір»сџрґрё!\n",
      "\n",
      "src: рћс‚ с—рґсѓс‚сњ...\n",
      "dst: рћс‚ с—рґсѓс‚сњ...\n",
      "\n",
      "src: вђ” рџрѕр»рѕр¶сѓ сџ, р»рёсѓрёс‡рєрѕ - сѓрµсѓс‚сђрёс‡рєрѕ, р№ с‚сђрµс‚сћ рѕс–р¶рєсѓ! вђ” рєр°р¶рµ рірѕрірє.\n",
      "dst: вђ” рџрѕр»рѕр¶сѓ сџ, р»рёсѓрёс‡рєрѕ – сѓрµсѓс‚сђрёс‡рєрѕ, р№ с‚сђрµс‚сћ рѕс–р¶рєсѓ! вђ” рєр°р¶рµ рірѕрірє.\n",
      "\n",
      "src: вђ” рљсѓрґрё с‚рё рїрѕр»рѕр¶рёс€? рўрё рјрµрѕс– сѓр°рѕрєрё рїрѕр»р°рјр°с”с€! р§рёрј сџ с‚рѕрґс– рґсђрѕрірµс†сњ рїсђрёрірµр·сѓ?\n",
      "dst: вђ” рљсѓрґрё с‚рё рїрѕр»рѕр¶рёс€? рўрё рјрµрѕс– сѓр°рѕрєрё рїрѕр»р°рјр°с”с€! р§рёрј , с‚рѕрґс– рґсђрѕрірµс†сњ рїсђрёрірµр·сѓ?\n",
      "\n",
      "src: вђ” рќс–, вђ” рєр°р¶рµ, вђ” рѕрµ рїрѕр»р°рјр°сћ.\n",
      "dst: вђ” рќс–, вђ” рєр°р¶рµ, вђ” рѕрµ рїрѕр»р°рјр°сћ.\n",
      "\n",
      "src: вђ” рќсѓ, рєр»р°рґрё.\n",
      "dst: вђ” рќсѓ, рєр»р°рґрё.\n",
      "\n",
      "src: р’рѕрірє рїрѕр»рѕр¶рёрі с– с‚сђрµс‚сћ рѕрѕрісѓ. рљрѕр»рё с†рµ вђ” с‚сђс–сѓсњ!\n",
      "dst: р’рѕрірє рїрѕр»рѕр¶рёрі с– с‚сђрµс‚сћ рѕрѕрісѓ. рљрѕр»рё с†рµ вђ” с‚сђс–сѓсњ!\n",
      "\n",
      "src: вђ” рћр№ р»рёс…рѕ! вђ” рєр°р¶рµ р»рёсѓрёс‡рєр°. вђ” р™рґрё сѓрѕр±с– рірµс‚сњ, рірѕріс‡рёрєсѓ, вђ” с‚рё рјрµрѕс– р·рѕрісѓс–рј сѓр°рѕрєрё рїрѕр»р°рјр°с”с€.\n",
      "dst: вђ” рћр№ р»рёс…рѕ! вђ” рєр°р¶рµ р»рёсѓрёс‡рєр°. вђ” р™рґрё сѓрѕр±с– рірµс‚сњ, рірѕріс‡рёрєсѓ, вђ” с‚рё рјрµрѕс– р·рѕрісѓс–рј сѓр°рѕрєрё рїрѕр»р°рјр°с”с€.\n",
      "\n",
      "src: вђ” рќс–, с‚рѕ сџ рѕсђс–с€рѕрє сђрѕр·рєсѓсѓрёрі!\n",
      "dst: вђ” рќс–, с‚рѕ , рѕсђс–с€рѕрє сђрѕр·рєсѓсѓрёрі!\n",
      "\n",
      "src: вђ” р”р°р№ р¶рµ р№ рјрµрѕс–!\n",
      "dst: вђ” р”р°р№ р¶рµ р№ рјрµрѕс–!\n",
      "\n",
      "src: вђ” рќрµрјр°, вђ” рєр°р¶рµ, вђ” рѕсѓс‚р°рѕрѕс–р№!\n",
      "dst: вђ” рќрµрјр°, вђ” рєр°р¶рµ, вђ” рѕсѓс‚р°рѕрѕс–р№!\n",
      "\n",
      "src: р‡рґсѓс‚сњ сѓрѕр±с– с‚р° р№ с—рґсѓс‚сњ; рірѕріс‡рёрє с– рєр°р¶рµ:\n",
      "dst: р‡рґсѓс‚сњ сѓрѕр±с– с‚р° р№ с—рґсѓс‚сњ; рірѕріс‡рёрє с– рєр°р¶рµ:\n",
      "\n",
      "src: вђ” рўсџрґсѓ сџ р·рѕрісѓс–рј, р»рёсѓрёс‡рєрѕ!\n",
      "dst: вђ” рўсџрґсѓ , р·рѕрісѓс–рј, р»рёсѓрёс‡рєрѕ!\n",
      "\n",
      "src: вђ” рљсѓрґрё с‚рё сѓсџрґрµс€, рірѕріс‡рёрєсѓ - р±сђр°с‚рёрєсѓ? р† сѓр°рѕрєрё сђрѕр·р»р°рјр°с”с€!\n",
      "dst: вђ” рљсѓрґрё с‚рё сѓсџрґрµс€, рірѕріс‡рёрєсѓ – р±сђр°с‚рёрєсѓ? р† сѓр°рѕрєрё сђрѕр·р»р°рјр°с”с€!\n",
      "\n",
      "src: вђ” рї рїрѕрјр°р»рµрѕсњрєсѓ, вђ” рєр°р¶рµ.\n",
      "dst: вђ” рї рїрѕрјр°р»рµрѕсњрєсѓ, вђ” рєр°р¶рµ.\n",
      "\n",
      "src: вђ” рќсѓ, рір»сџрґрё!\n",
      "dst: вђ” рќсѓ, рір»сџрґрё!\n",
      "\n",
      "src: рћс‚ рірѕріс‡рёрє с‚с–р»сњрєрё с‰рѕ сѓс–рі, р° сѓр°рѕрєрё с‚р°рє с– сђрѕр·рїр°р»рёсѓсњ... р›рёсѓрёс‡рєр° с‚рѕрґс– рґр°рір°р№ р№рѕрірѕ р»р°сџс‚сњ! р›р°сџр»р° - р»р°сџр»р° с‚р° р№ рєр°р¶рµ:\n",
      "dst: рћс‚ рірѕріс‡рёрє с‚с–р»сњрєрё с‰рѕ сѓс–рі, р° сѓр°рѕрєрё с‚р°рє с– сђрѕр·рїр°р»рёсѓсњ... р›рёсѓрёс‡рєр° с‚рѕрґс– рґр°рір°р№ р№рѕрірѕ р»р°сџс‚сњ! р›р°сџр»р° – р»р°сџр»р° с‚р° р№ рєр°р¶рµ:\n",
      "\n",
      "src: вђ” рџс–рґрё р¶, сѓсџрєрёр№ - с‚р°рєрёр№ сѓрёрѕсѓ, рґсђрѕрірµс†сњ рѕр°сђсѓр±р°р№ с– рѕр° сѓр°рѕрєрё рірёсђсѓр±р°р№, с– рїсђрёрірѕр»рѕс‡рё!\n",
      "dst: вђ” рџс–рґрё р¶, сѓсџрєрёр№ – с‚р°рєрёр№ сѓрёрѕсѓ, рґсђрѕрірµс†сњ рѕр°сђсѓр±р°р№ с– рѕр° сѓр°рѕрєрё рірёсђсѓр±р°р№, с– рїсђрёрірѕр»рѕс‡рё!\n",
      "\n",
      "src: вђ” рїрє р¶рµ сџ, вђ” рєр°р¶рµ рірѕріс‡рёрє, вђ” рірёсђсѓр±р°сћ, рєрѕр»рё сџ рѕрµ р·рѕр°сћ, сџрєрѕрірѕ рґрµсђрµрір°?\n",
      "dst: вђ” рїрє р¶рµ сџ, вђ” рєр°р¶рµ рірѕріс‡рёрє, вђ” рірёсђсѓр±р°сћ, рєрѕр»рё , рѕрµ р·рѕр°сћ, сџрєрѕрірѕ рґрµсђрµрір°?\n",
      "\n",
      "src: вђ” р•, вђ” сѓсџрєрёр№ - с‚р°рєрёр№ сѓрёрѕсѓ! рїрє сѓр°рѕс‡р°с‚р° р»р°рјр°с‚сњ, с‚р°рє с– р·рѕр°рі, р° рґсђрѕрірµс†сњ рірёсђсѓр±р°с‚сњ, с‚рѕ р№ рѕс–!\n",
      "dst: вђ” р•, вђ” сѓсџрєрёр№ – с‚р°рєрёр№ сѓрёрѕсѓ! рїрє сѓр°рѕс‡р°с‚р° р»р°рјр°с‚сњ, с‚р°рє с– р·рѕр°рі, р° рґсђрѕрірµс†сњ рірёсђсѓр±р°с‚сњ, с‚рѕ р№ рѕс–!\n",
      "\n",
      "src: рљрѕсђрёс€сѓрір°р»р° р№рѕрірѕ, рєрѕсђрёс€сѓрір°р»р°...\n",
      "dst: рљрѕсђрёс€сѓрір°р»р° р№рѕрірѕ, рєрѕсђрёс€сѓрір°р»р°...\n",
      "\n",
      "src: вђ” рїрє сѓріс–р№рґрµс€, вђ” рєр°р¶рµ, вђ” рі р»с–сѓ, с‚рѕ рєр°р¶рё: в« р сѓр±р°р№сѓсџ, рґрµсђрµрірѕ, р№ рїсђсџрјрµ, р№ рєсђрёрірµ! р сѓр±р°р№сѓсџ, рґрµсђрµрірѕ, р№ рїсђсџрјрµ, р№ рєсђрёрірµ! в»\n",
      "dst: вђ” рїрє сѓріс–р№рґрµс€, вђ” рєр°р¶рµ, вђ” пя р»с–сѓ, с‚рѕ рєр°р¶рё: в« во сѓр±р°р№сѓсџ, рґрµсђрµрірѕ, р№ рїсђсџрјрµ, р№ рєсђрёрірµ! во сѓр±р°р№сѓсџ, рґрµсђрµрірѕ, р№ рїсђсџрјрµ, р№ рєсђрёрірµ! в»\n",
      "\n",
      "src: р’рѕрірє с– рїс–с€рѕрі.\n",
      "dst: р’рѕрірє с– рїс–с€рѕрі.\n",
      "\n",
      "src: рћс‚ рїсђрёс…рѕрґрёс‚сњ рі р»с–сѓ с‚р° р№ рєр°р¶рµ:\n",
      "dst: рћс‚ рїсђрёс…рѕрґрёс‚сњ пя р»с–сѓ с‚р° р№ рєр°р¶рµ:\n",
      "\n",
      "src: вђ” р сѓр±р°р№сѓсџ, рґрµсђрµрірѕ, рєсђрёрірµ р№ рєсђрёрірµ!\n",
      "dst: вђ” во сѓр±р°р№сѓсџ, рґрµсђрµрірѕ, рєсђрёрірµ р№ рєсђрёрірµ!\n",
      "\n",
      "src: р”рµсђрµрірѕ р№ рѕр°сђсѓр±р°р»рѕсѓсњ. рўр°рєрµ рєрѕсђсџс‡рєсѓрір°с‚рµ, с‰рѕ р№ рѕр° рїр°р»рёс†сћ рѕрµ рірёр±рµсђрµс€ вђ” рѕрµ с‚рѕ рѕр° рїрѕр»рѕр·рѕрє! рџсђрёрѕрѕсѓрёс‚сњ рірѕріс‡рёрє рґрѕ р»рёсѓрёс‡рєрё с‚рµ рґрµсђрµрірѕ. р’рѕрѕр° сџрє рїрѕрґрёрірёр»р°сѓсњ, рґр°рір°р№ р№рѕрірѕ р·рѕрѕрі р±р°с‚сњрєсѓрір°с‚рё.\n",
      "dst: р”рµсђрµрірѕ р№ рѕр°сђсѓр±р°р»рѕсѓсњ. рўр°рєрµ рєрѕсђсџс‡рєсѓрір°с‚рµ, с‰рѕ р№ рѕр° рїр°р»рёс†сћ рѕрµ рірёр±рµсђрµс€ вђ” рѕрµ с‚рѕ рѕр° рїрѕр»рѕр·рѕрє! рџсђрёрѕрѕсѓрёс‚сњ рірѕріс‡рёрє рґрѕ р»рёсѓрёс‡рєрё с‚рµ рґрµсђрµрірѕ. р’рѕрѕр° сџрє рїрѕрґрёрірёр»р°сѓсњ, рґр°рір°р№ р№рѕрірѕ р·рѕрѕрі р±р°с‚сњрєсѓрір°с‚рё.\n",
      "\n",
      "src: вђ” рўрё, вђ” рєр°р¶рµ, вђ” сѓсџрєрёр№ - с‚р°рєрёр№ сѓрёрѕсѓ, рѕрµ с‚р°рє рєр°р·р°рі, сџрє сџ с‚рѕр±с– рірµр»с–р»р°!\n",
      "dst: вђ” рўрё, вђ” рєр°р¶рµ, вђ” сѓсџрєрёр№ – с‚р°рєрёр№ сѓрёрѕсѓ, рѕрµ с‚р°рє рєр°р·р°рі, сџрє , с‚рѕр±с– рірµр»с–р»р°!\n",
      "\n",
      "src: вђ” рќс–, р»рёсѓрёс‡рєрѕ - сѓрµсѓс‚сђрёс‡рєрѕ, сџ, вђ” рєр°р¶рµ, вђ” сѓс‚рѕсџрі с‚р° рісѓрµ рєр°р·р°рі: в« р сѓр±р°р№сѓсџ, рґрµсђрµрірѕ, рєсђрёрірµ р№ рєсђрёрірµ! в»\n",
      "dst: вђ” рќс–, р»рёсѓрёс‡рєрѕ – сѓрµсѓс‚сђрёс‡рєрѕ, сџ, вђ” рєр°р¶рµ, вђ” сѓс‚рѕсџрі с‚р° рісѓрµ рєр°р·р°рі: в« во сѓр±р°р№сѓсџ, рґрµсђрµрірѕ, рєсђрёрірµ р№ рєсђрёрірµ! в»\n",
      "\n",
      "src: вђ” р•, р±с–сѓс–рі сѓрёрѕсѓ, р№ с‚рѕрірѕ рѕрµрґрѕс‚рµрїрѕрёр№! рќсѓ, сѓрёрґрё р¶ с‚рё с‚сѓс‚, вђ” сџ сѓр°рјр° рїс–рґсѓ рѕр°сђсѓр±р°сћ.\n",
      "dst: вђ” р•, р±с–сѓс–рі сѓрёрѕсѓ, р№ с‚рѕрірѕ рѕрµрґрѕс‚рµрїрѕрёр№! рќсѓ, сѓрёрґрё р¶ с‚рё с‚сѓс‚, вђ” , сѓр°рјр° рїс–рґсѓ рѕр°сђсѓр±р°сћ.\n",
      "\n",
      "src: рўр° р№ рїс–с€р»р°.\n",
      "dst: рўр° р№ рїс–с€р»р°.\n",
      "\n",
      "src: рћс‚ сѓрёрґрёс‚сњ рірѕрірє сѓр°рј сѓрѕр±с– вђ” с‚р°рє с—сѓс‚рё с…рѕс‡рµс‚сњсѓсџ! р’с–рѕ рґсѓрјр°рі - рґсѓрјр°рі: в« р”р°рір°р№, вђ” рєр°р¶рµ, вђ” р·вђ™с—рј р±рёс‡рєр° с‚р° р№ сѓс‚рµс‡сѓ! в» рћс‚ рір·сџрі рїсђрѕс—рі рґс–сђрєсѓ сѓ р±рёс‡рєр°, с–р· сѓрµсђрµрґрёрѕрё рісѓрµ рірёс—рі, р° с‚сѓрґрё рірѕсђрѕр±с†с–рі рѕр°рїсѓсѓс‚рёрі с– сѓрѕр»рѕрјрѕсћ р·р°с‚рєрѕсѓрі, р° сѓр°рј вђ” рґсђр°р»р°... рџсђрёс…рѕрґрёс‚сњ р»рёсѓрёс‡рєр°, р·сђрѕр±рёр»р° сѓр°рѕс‡р°с‚р°, сѓс–р»р°...\n",
      "dst: рћс‚ сѓрёрґрёс‚сњ рірѕрірє сѓр°рј сѓрѕр±с– вђ” с‚р°рє с—сѓс‚рё с…рѕс‡рµс‚сњсѓсџ! р’с–рѕ рґсѓрјр°рі – рґсѓрјр°рі: в« р”р°рір°р№, вђ” рєр°р¶рµ, вђ” р·вђ™с—рј р±рёс‡рєр° с‚р° р№ сѓс‚рµс‡сѓ! в» рћс‚ рір·сџрі рїсђрѕс—рі рґс–сђрєсѓ сѓ р±рёс‡рєр°, с–р· сѓрµсђрµрґрёрѕрё рісѓрµ рірёс—рі, р° с‚сѓрґрё рірѕсђрѕр±с†с–рі рѕр°рїсѓсѓс‚рёрі с– сѓрѕр»рѕрјрѕсћ р·р°с‚рєрѕсѓрі, р° сѓр°рј вђ” рґсђр°р»р°... рџсђрёс…рѕрґрёс‚сњ р»рёсѓрёс‡рєр°, р·сђрѕр±рёр»р° сѓр°рѕс‡р°с‚р°, сѓс–р»р°...\n",
      "\n",
      "src: вђ” р“рµр№, р±рёс‡рѕрє - с‚сђрµс‚сџс‡рѕрє!\n",
      "dst: вђ” р“рµр№, р±рёс‡рѕрє – с‚сђрµс‚сџс‡рѕрє!\n",
      "\n",
      "src: рђр¶ р±рёс‡рѕрє рѕрµ рірµр·рµ. р’рѕрѕр° р№рѕрірѕ р±р°с‚рѕрірѕрј. рїрє сѓрґр°сђрёр»р°, р° ріс–с…рѕс‚сњ сѓрѕр»рѕрјрё р№ рірёрїр°рі; р° рірѕсђрѕр±с†с– вђ” с…сђсђсђ!\n",
      "dst: рђр¶ р±рёс‡рѕрє рѕрµ рірµр·рµ. р’рѕрѕр° р№рѕрірѕ р±р°с‚рѕрірѕрј. рїрє сѓрґр°сђрёр»р°, р° ріс–с…рѕс‚сњ сѓрѕр»рѕрјрё р№ рірёрїр°рі; р° рірѕсђрѕр±с†с– вђ” с…сђсђсђ!\n",
      "\n",
      "src: вђ” рђ, сѓсџрєрёр№ - с‚р°рєрёр№ рірѕріс‡рёрє! рџрѕсѓс‚с–р№ р¶рµ, вђ” рєр°р¶рµ, вђ” сџ с‚рѕр±с– р·рір°рґр°сћ!\n",
      "dst: вђ” рђ, сѓсџрєрёр№ – с‚р°рєрёр№ рірѕріс‡рёрє! рџрѕсѓс‚с–р№ р¶рµ, вђ” рєр°р¶рµ, вђ” , с‚рѕр±с– р·рір°рґр°сћ!\n",
      "\n",
      "src: рўр° р№ рїс–с€р»р°...\n",
      "dst: рўр° р№ рїс–с€р»р°...\n",
      "\n",
      "src: р›сџрір»р° рѕр° с€р»сџс…сѓ с‚р° р№ р»рµр¶рёс‚сњ. р†рґсѓс‚сњ с‡сѓрјр°рєрё р· сђрёр±рѕсћ; рірѕрѕр° рїсђрёс‚р°с—р»р°сѓсњ, рјрѕрі рѕрµр¶рёрір°. р§сѓрјр°рєрё рґрёрір»сџс‚сњсѓсџ вђ” р°р¶ р»рёсѓрёс†сџ:\n",
      "dst: р›сџрір»р° рѕр° с€р»сџс…сѓ с‚р° р№ р»рµр¶рёс‚сњ. р†рґсѓс‚сњ с‡сѓрјр°рєрё р· сђрёр±рѕсћ; рірѕрѕр° рїсђрёс‚р°с—р»р°сѓсњ, рјрѕрі рѕрµр¶рёрір°. р§сѓрјр°рєрё рґрёрір»сџс‚сњсѓсџ вђ” р°р¶ р»рёсѓрёс†сџ:\n",
      "\n",
      "src: вђ” р’с–р·сњрјс–рј, вђ” рєр°р¶сѓс‚сњ, вђ” р±сђр°, с‚р° рїсђрѕрґр°рјрѕ вђ” р±сѓрґрµ р·р° с‰рѕ с…рѕс‡ рїрѕрісђс–с‚рёсѓсџ!\n",
      "dst: вђ” р’с–р·сњрјс–рј, вђ” рєр°р¶сѓс‚сњ, вђ” р±сђр°, с‚р° рїсђрѕрґр°рјрѕ вђ” р±сѓрґрµ р·р° с‰рѕ с…рѕс‡ рїрѕрісђс–с‚рёсѓсџ!\n",
      "\n",
      "src: рўрєрёрѕсѓр»рё с—с— рѕр° рѕсѓс‚р°рѕрѕс–р№ ріс–р· с‚р° р№ рїрѕс—с…р°р»рё. р†рґсѓс‚сњ с‚р° р№ с—рґсѓс‚сњ. рђ р»рёсѓрёс‡рєр° - сѓрµсѓс‚сђрёс‡рєр° р±р°с‡рёс‚сњ, с‰рѕ рірѕрѕрё рѕрµ рґрёрір»сџс‚сњсѓсџ, с‚р° рісѓрµ рєрёрґр° рїрѕ сђрёр±с†с– рѕр° рґрѕсђрѕрісѓ, рісѓрµ рєрёрґр°... рћс‚ сџрє рѕр°рєрёрґр°р»р° рір¶рµ р±р°рір°с‚рѕ, с‚рѕрґс– рѕрёс€рєрѕрј с– сѓр°рјр° р·р»с–р·р»р°. р§сѓрјр°рєрё р¶ рїрѕс—с…р°р»рё сѓрѕр±с– рґр°р»с–, р° рірѕрѕр° рїрѕр·р±рёсђр°р»р° сђрёр±рєсѓ, сѓс–р»р° с‚р° р№ с—сѓс‚сњ.\n",
      "dst: рўрєрёрѕсѓр»рё с—с— рѕр° рѕсѓс‚р°рѕрѕс–р№ ріс–р· с‚р° р№ рїрѕс—с…р°р»рё. р†рґсѓс‚сњ с‚р° р№ с—рґсѓс‚сњ. рђ р»рёсѓрёс‡рєр° – сѓрµсѓс‚сђрёс‡рєр° р±р°с‡рёс‚сњ, с‰рѕ рірѕрѕрё рѕрµ рґрёрір»сџс‚сњсѓсџ, с‚р° рісѓрµ рєрёрґр° рїрѕ сђрёр±с†с– рѕр° рґрѕсђрѕрісѓ, рісѓрµ рєрёрґр°... рћс‚ сџрє рѕр°рєрёрґр°р»р° рір¶рµ р±р°рір°с‚рѕ, с‚рѕрґс– рѕрёс€рєрѕрј с– сѓр°рјр° р·р»с–р·р»р°. р§сѓрјр°рєрё р¶ рїрѕс—с…р°р»рё сѓрѕр±с– рґр°р»с–, р° рірѕрѕр° рїрѕр·р±рёсђр°р»р° сђрёр±рєсѓ, сѓс–р»р° с‚р° р№ с—сѓс‚сњ.\n",
      "\n",
      "src: рљрѕр»рё с†рµ р±с–р¶рёс‚сњ рірѕріс‡рёрє:\n",
      "dst: рљрѕр»рё с†рµ р±с–р¶рёс‚сњ рірѕріс‡рёрє:\n",
      "\n",
      "src: вђ” р—рґрѕсђрѕрір° р±сѓр»р°, р»рёсѓрёс‡рєрѕ - сѓрµсѓс‚сђрёс‡рєрѕ!\n",
      "dst: вђ” р—рґрѕсђрѕрір° р±сѓр»р°, р»рёсѓрёс‡рєрѕ – сѓрµсѓс‚сђрёс‡рєрѕ!\n",
      "\n",
      "src: вђ” р—рґрѕсђрѕрі, рірѕріс‡рёрєсѓ - р±сђр°с‚рёрєсѓ!\n",
      "dst: вђ” р—рґрѕсђрѕрі, рірѕріс‡рёрєсѓ – р±сђр°с‚рёрєсѓ!\n",
      "\n",
      "src: вђ” р©рѕ с‚рё сђрѕр±рёс€, р»рёсѓрёс‡рєрѕ - сѓрµсѓс‚сђрёс‡рєрѕ?\n",
      "dst: вђ” р©рѕ с‚рё сђрѕр±рёс€, р»рёсѓрёс‡рєрѕ – сѓрµсѓс‚сђрёс‡рєрѕ?\n",
      "\n",
      "src: вђ” р рёр±сѓ, вђ” рєр°р¶рµ, вђ” с—рј.\n",
      "dst: вђ” во рёр±сѓ, вђ” рєр°р¶рµ, вђ” с—рј.\n",
      "\n",
      "src: вђ” р”р°р№ р¶рµ р№ рјрµрѕс–!\n",
      "dst: вђ” р”р°р№ р¶рµ р№ рјрµрѕс–!\n",
      "\n",
      "src: вђ” рџс–рґрё сѓрѕр±с– рѕр°р»рѕрірё.\n",
      "dst: вђ” рџс–рґрё сѓрѕр±с– рѕр°р»рѕрірё.\n",
      "\n",
      "src: вђ” рўр°рє сџрє р¶рµ сџ рѕр°р»рѕрір»сћ, рєрѕр»рё сџ рѕрµ рірјс–сћ?\n",
      "dst: вђ” рўр°рє сџрє р¶рµ , рѕр°р»рѕрір»сћ, рєрѕр»рё , рѕрµ рірјс–сћ?\n",
      "\n",
      "src: вђ” рќсѓ, сџрє р·рѕр°с”с€, р° сџ рѕрµ рґр°рј с– рєс–сѓс‚рѕс‡рєрё!\n",
      "dst: вђ” рќсѓ, сџрє р·рѕр°с”с€, р° , рѕрµ рґр°рј с– рєс–сѓс‚рѕс‡рєрё!\n",
      "\n",
      "src: вђ” рўр°рє с…рѕс‡ рѕр°ріс‡рё рјрµрѕрµ, сџрє рѕр°р»рѕрірёс‚сњ.\n",
      "dst: вђ” рўр°рє с…рѕс‡ рѕр°ріс‡рё рјрµрѕрµ, сџрє рѕр°р»рѕрірёс‚сњ.\n",
      "\n",
      "src: рђ р»рёсѓрёс‡рєр° р№ рґсѓрјр°: в« рџрѕсѓс‚с–р№ р¶рµ! рўрё рјрѕрірѕ р±рёс‡рєр° - с‚сђрµс‚сџс‡рєр° р·вђ™с—рі вђ” сџ с‚рµрїрµсђ с‚рѕр±с– рѕрґрґсџс‡сѓ! в»\n",
      "dst: рђ р»рёсѓрёс‡рєр° р№ рґсѓрјр°: в« рџрѕсѓс‚с–р№ р¶рµ! рўрё рјрѕрірѕ р±рёс‡рєр° – с‚сђрµс‚сџс‡рєр° р·вђ™с—рі вђ” , с‚рµрїрµсђ с‚рѕр±с– рѕрґрґсџс‡сѓ! в»\n",
      "\n",
      "src: вђ” рђ с‚р°рє, вђ” рєр°р¶рµ, вђ” рїс–рґрё рґрѕ рѕрїрѕр»рѕрѕрєрё, сѓсѓс‚сђрѕрјрё рі рѕрїрѕр»рѕрѕрєсѓ с…ріс–сѓс‚ с‚р° рїрѕс‚рёс…рµрѕсњрєсѓ рірѕрґрё рѕрёрј с– рїсђрёрєр°р·сѓр№: в« р›рѕрірёсѓсњ, сђрёр±рєрѕ, рјр°р»р° р№ рірµр»рёрєр°! р›рѕрірёсѓсњ, сђрёр±рєрѕ, рјр°р»р° р№ рірµр»рёрєр°! в» рўрѕ рірѕрѕр° р№ рѕр°р»рѕрірёс‚сњсѓсџ.\n",
      "dst: вђ” рђ с‚р°рє, вђ” рєр°р¶рµ, вђ” рїс–рґрё рґрѕ рѕрїрѕр»рѕрѕрєрё, сѓсѓс‚сђрѕрјрё пя рѕрїрѕр»рѕрѕрєсѓ с…ріс–сѓс‚ с‚р° рїрѕс‚рёс…рµрѕсњрєсѓ рірѕрґрё рѕрёрј с– рїсђрёрєр°р·сѓр№: в« р›рѕрірёсѓсњ, сђрёр±рєрѕ, рјр°р»р° р№ рірµр»рёрєр°! р›рѕрірёсѓсњ, сђрёр±рєрѕ, рјр°р»р° р№ рірµр»рёрєр°! в» рўрѕ рірѕрѕр° р№ рѕр°р»рѕрірёс‚сњсѓсџ.\n",
      "\n",
      "src: вђ” рќсѓ, сѓрїр°сѓрёр±с– р·р° рѕр°сѓрєсѓ! вђ” рєр°р¶рµ рірѕріс‡рёрє.\n",
      "dst: вђ” рќсѓ, сѓрїр°сѓрёр±с– р·р° рѕр°сѓрєсѓ! вђ” рєр°р¶рµ рірѕріс‡рёрє.\n",
      "\n",
      "src: рћс‚ рїсђрёр±с–рір°с” рірѕріс‡рёрє рґрѕ рѕрїрѕр»рѕрѕрєрё, сѓсѓс‚сђрѕрјрёрі рі рѕрїрѕр»рѕрѕрєсѓ с…ріс–сѓс‚:\n",
      "dst: рћс‚ рїсђрёр±с–рір°с” рірѕріс‡рёрє рґрѕ рѕрїрѕр»рѕрѕрєрё, сѓсѓс‚сђрѕрјрёрі пя рѕрїрѕр»рѕрѕрєсѓ с…ріс–сѓс‚:\n",
      "\n",
      "src: вђ” р›рѕрірёсѓсњ, вђ” рєр°р¶рµ, вђ” сђрёр±рєрѕ, рјр°р»р° р№ рірµр»рёрєр°!\n",
      "dst: вђ” р›рѕрірёсѓсњ, вђ” рєр°р¶рµ, вђ” сђрёр±рєрѕ, рјр°р»р° р№ рірµр»рёрєр°!\n",
      "\n",
      "src: рђ р»рёсѓрёс‡рєр° р· рѕс‡рµсђрµс‚сѓ:\n",
      "dst: рђ р»рёсѓрёс‡рєр° р· рѕс‡рµсђрµс‚сѓ:\n",
      "\n",
      "src: вђ” рњрµсђр·рѕрё, рјрµсђр·рѕрё, рірѕріс‡рёр№ с…ріс–сѓс‚!\n",
      "dst: вђ” рњрµсђр·рѕрё, рјрµсђр·рѕрё, рірѕріс‡рёр№ с…ріс–сѓс‚!\n",
      "\n",
      "src: рђ рјрѕсђрѕр· рѕр°рґрірѕсђс– с‚р°рєрёр№, с‰рѕ р°р¶ с€рєрір°сђс‡рёс‚сњ! р’рѕріс‡рёрє с…рірѕсѓс‚рёрєрѕрј сѓсѓрµ рірѕрґрёс‚сњ с‚р°:\n",
      "dst: рђ рјрѕсђрѕр· рѕр°рґрірѕсђс– с‚р°рєрёр№, с‰рѕ р°р¶ с€рєрір°сђс‡рёс‚сњ! р’рѕріс‡рёрє с…рірѕсѓс‚рёрєрѕрј сѓсѓрµ рірѕрґрёс‚сњ с‚р°:\n",
      "\n",
      "src: вђ” р›рѕрірёсѓсњ, сђрёр±рєрѕ, рјр°р»р° р№ рірµр»рёрєр°!\n",
      "dst: вђ” р›рѕрірёсѓсњ, сђрёр±рєрѕ, рјр°р»р° р№ рірµр»рёрєр°!\n",
      "\n",
      "src: рђ р»рёсѓрёс‡рєр°:\n",
      "dst: рђ р»рёсѓрёс‡рєр°:\n",
      "\n",
      "src: вђ” рњрµсђр·рѕрё, рјрµсђр·рѕрё, рірѕріс‡рёр№ с…ріс–сѓс‚!\n",
      "dst: вђ” рњрµсђр·рѕрё, рјрµсђр·рѕрё, рірѕріс‡рёр№ с…ріс–сѓс‚!\n",
      "\n",
      "src: рџрѕрєрё р»рѕрірёрі рірѕріс‡рёрє сђрёр±сѓ, рїрѕрєрё с…ріс–сѓс‚ с‚р°рє с– рїсђрёрєрёрїс–рі рі рѕрїрѕр»рѕрѕс†с–! рўрѕрґс– р»рёсѓрёс‡рєр° рі сѓрµр»рѕ:\n",
      "dst: рџрѕрєрё р»рѕрірёрі рірѕріс‡рёрє сђрёр±сѓ, рїрѕрєрё с…ріс–сѓс‚ с‚р°рє с– рїсђрёрєрёрїс–рі пя рѕрїрѕр»рѕрѕс†с–! рўрѕрґс– р»рёсѓрёс‡рєр° пя сѓрµр»рѕ:\n",
      "\n",
      "src: вђ” р†рґс–с‚сњ, р»сћрґрё, рірѕрірєр° р±рёс‚сњ!\n",
      "dst: вђ” р†рґс–с‚сњ, р»сћрґрё, рірѕрірєр° р±рёс‚сњ!\n",
      "\n",
      "src: р›сћрґрё сџрє рірёсѓрєрѕс‡р°с‚сњ вђ” р· рєрѕс‡рµсђрір°рјрё, р· сђрѕрір°с‡р°рјрё, с–р· сѓрѕрєрёсђр°рјрё: рір±рёр»рё с‚рѕрірѕ рірѕрірєр° с– рїсђрѕрїр°рі р±с–рґрѕрёр№! рђ р»рёсѓрёс‡рєр° р№ рґрѕсѓс– р¶рёрірµ сѓ сѓрірѕс—р№ с…р°с‚с†с–.\n",
      "dst: р›сћрґрё сџрє рірёсѓрєрѕс‡р°с‚сњ вђ” р· рєрѕс‡рµсђрір°рјрё, р· сђрѕрір°с‡р°рјрё, с–р· сѓрѕрєрёсђр°рјрё: рір±рёр»рё с‚рѕрірѕ рірѕрірєр° с– рїсђрѕрїр°рі р±с–рґрѕрёр№! рђ р»рёсѓрёс‡рєр° р№ рґрѕсѓс– р¶рёрірµ сѓ сѓрірѕс—р№ с…р°с‚с†с–.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in uk_sentences:\n",
    "    print(\"src: {}\\ndst: {}\\n\".format(sentence, translate(sentence)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not so bad, right? We can easily improve translation using language model and not one but several nearest neighbours in shared embedding space. But next time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Task)  7 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Download embedding from here: https://fasttext.cc/docs/en/crawl-vectors.html (download text format). Depending on the group, choose the correct Slavic language embedding. After downloading and using the embedding, repeat all the tasks from first part, but you dont need set asserts in this task and generate the same simple text (at least 200 words) and translate it into Russian.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Would you like to learn more?\n",
    "\n",
    "### Articles:\n",
    "* [Exploiting Similarities among Languages for Machine Translation](https://arxiv.org/pdf/1309.4168)  - entry point for multilingual embedding studies by Tomas Mikolov (the author of W2V)\n",
    "* [Offline bilingual word vectors, orthogonal transformations and the inverted softmax](https://arxiv.org/pdf/1702.03859) - orthogonal transform for unsupervised MT\n",
    "* [Word Translation Without Parallel Data](https://arxiv.org/pdf/1710.04087)\n",
    "* [Loss in Translation: Learning Bilingual Word Mapping with a Retrieval Criterion](https://arxiv.org/pdf/1804.07745)\n",
    "* [Unsupervised Alignment of Embeddings with Wasserstein Procrustes](https://arxiv.org/pdf/1805.11222)\n",
    "\n",
    "### Repos (with ready-to-use multilingual embeddings):\n",
    "* https://github.com/facebookresearch/MUSE\n",
    "\n",
    "* https://github.com/Babylonpartners/fastText_multilingual -"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
